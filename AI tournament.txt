#!/usr/bin/env python3
"""
üèÜ ULTIMATE AI TRADING TOURNAMENT - KIMI API EDITION
=============================================================

Replaced OpenAI with Kimi API from Moonshot AI
Enhanced with: Market regimes, exit type classification, experiment tracking
Architecture: AI ‚Üí Reviewer ‚Üí Portfolio ‚Üí Labeled Outcomes ‚Üí Retraining
"""

# ============================================================================
# IMPORTS & DEPENDENCIES
# ============================================================================

import os
import sys
import json
import time
import sqlite3
import logging
import argparse
import hashlib
import warnings
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import defaultdict
from pathlib import Path

warnings.filterwarnings("ignore")

# Core Dependencies
try:
    import yfinance as yf
    import pandas as pd
    import numpy as np
except ImportError as e:
    print(f"‚ùå Missing: {e}")
    print("Install: pip install yfinance pandas numpy")
    sys.exit(1)

# AI API Dependencies (Kimi API uses OpenAI-compatible interface)
try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

try:
    # Kimi API uses OpenAI client with Moonshot's base URL
    from openai import OpenAI
except ImportError:
    OpenAI = None

try:
    import google.generativeai as genai
except ImportError:
    genai = None

try:
    import chromadb
    from chromadb.utils import embedding_functions
except ImportError:
    chromadb = None
    embedding_functions = None

# ============================================================================
# ENUMS & DATA STRUCTURES
# ============================================================================

class TradeAction(Enum):
    BUY = "BUY"
    SELL = "SELL"
    HOLD = "HOLD"
    STRONG_BUY = "STRONG_BUY"
    STRONG_SELL = "STRONG_SELL"

class PositionStatus(Enum):
    OPEN = "OPEN"
    CLOSED = "CLOSED"
    STOPPED = "STOPPED"
    TARGET_HIT = "TARGET_HIT"
    EXPIRED = "EXPIRED"

class TradeQuality(Enum):
    EXCELLENT = "excellent"
    GOOD = "good"
    NEUTRAL = "neutral"
    POOR = "poor"
    TERRIBLE = "terrible"

class ReviewDecision(Enum):
    APPROVE = "approve"
    MODIFY = "modify"
    REJECT = "reject"
    HOLD = "hold"

class MarketRegime(Enum):
    """Market regime tags for enhanced labeling"""
    HIGH_VOL = "high_vol"
    LOW_VOL = "low_vol"
    RISK_ON = "risk_on"
    RISK_OFF = "risk_off"
    NORMAL = "normal"

class ExitType(Enum):
    """How the trade was closed"""
    STOP_LOSS = "stop_loss"
    TARGET_HIT = "target_hit"
    TIME_EXPIRED = "time_expired"
    DISCRETIONARY = "discretionary"  # Manual close by reviewer

@dataclass
class StockData:
    symbol: str
    price: float
    change_1d: float
    change_5d: float
    volume_ratio: float
    rsi: float
    above_ma50: bool
    above_ma200: bool
    market_cap: float
    atr: Optional[float] = None
    timestamp: datetime = field(default_factory=datetime.now)
    sector: str = "unknown"

@dataclass
class FilterResult:
    symbol: str
    score: float
    signals: List[str]
    stock_data: StockData
    priority: int

@dataclass
class VirtualPortfolio:
    team_id: int
    team_name: str
    initial_capital: float
    cash: float
    positions: Dict[str, 'VirtualPosition'] = field(default_factory=dict)
    closed_positions: List['VirtualPosition'] = field(default_factory=list)
    
    total_value: float = 0.0
    peak_value: float = 0.0
    max_drawdown: float = 0.0
    
    daily_pnl: float = 0.0
    total_pnl: float = 0.0
    total_return_pct: float = 0.0
    
    winning_trades: int = 0
    losing_trades: int = 0
    total_trades: int = 0
    
    api_costs: float = 0.0
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    calmar_ratio: float = 0.0
    recovery_factor: float = 0.0
    success_rate: float = 0.0
    avg_pnl: float = 0.0
    
    # NEW: Track current market regime
    current_regime: MarketRegime = MarketRegime.NORMAL
    
    def __post_init__(self):
        self.logger = logging.getLogger(self.team_name)

    def update_portfolio_value(self, current_prices: Dict[str, float]):
        self.total_value = self.cash
        for symbol, pos in self.positions.items():
            if symbol in current_prices:
                pos.update_market_price(current_prices[symbol])
                self.total_value += pos.position_value + (pos.unrealized_pnl or 0)
        
        if self.total_value > self.peak_value:
            self.peak_value = self.total_value
        
        drawdown = (self.total_value - self.peak_value) / self.peak_value
        if drawdown < self.max_drawdown:
            self.max_drawdown = drawdown
        
        self.total_return_pct = (self.total_value - self.initial_capital) / self.initial_capital * 100
    
    def can_open_position(self, proposed_value: float) -> bool:
        if proposed_value > self.cash:
            return False
        if len(self.positions) >= 15:
            return False
        
        daily_risk = sum(
            pos.position_value * (0.02 if not pos.atr_at_entry else pos.atr_at_entry / pos.entry_price)
            for pos in self.positions.values()
        )
        max_daily_risk = self.total_value * 0.02
        if daily_risk + (proposed_value * 0.02) > max_daily_risk:
            return False
        
        return True

    def calculate_position_size(self, rec: 'TeamRecommendation', current_price: float,
                              atr: float, confidence_adjustment: float = 0.0) -> int:
        adjusted_confidence = rec.confidence + confidence_adjustment
        adjusted_confidence = max(30, min(100, adjusted_confidence))
        
        risk_per_trade = self.total_value * 0.02
        stop_distance = atr * 2.0 if atr else current_price * 0.08
        shares_from_risk = int(risk_per_trade / stop_distance) if stop_distance > 0 else 0
        
        kelly_multiplier = adjusted_confidence / 100.0
        conservative_shares = int(shares_from_risk * kelly_multiplier * 0.25)
        max_shares = int((self.total_value * 0.10) / current_price)
        
        return min(conservative_shares, max_shares)
    
    def open_position(self, rec: 'TeamRecommendation', current_price: float, 
                     atr: float, confidence_adjustment: float, size_modifier: float) -> bool:
        """Open a new position based on recommendation"""
        if not self.can_open_position(current_price * 100):  # Check with minimum shares
            return False
        
        shares = self.calculate_position_size(rec, current_price, atr, confidence_adjustment)
        shares = int(shares * size_modifier)
        
        if shares <= 0:
            return False
        
        position_value = shares * current_price
        if position_value > self.cash:
            return False
        
        position = VirtualPosition(
            position_id=f"pos_{int(time.time())}_{rec.team_id}_{rec.symbol}",
            recommendation_id=rec.recommendation_id,
            team_id=rec.team_id,
            symbol=rec.symbol,
            action=rec.action,
            entry_price=current_price,
            entry_timestamp=datetime.now(),
            position_size_shares=shares,
            position_value=position_value,
            confidence_at_entry=rec.confidence,
            reasoning=rec.reasoning,
            key_factors=rec.key_factors,
            atr_at_entry=atr,
            stop_loss=rec.stop_loss,
            target_price=rec.target_price,
            current_price=current_price
        )
        
        self.positions[rec.symbol] = position
        self.cash -= position_value
        return True
    
    def close_position(self, symbol: str, exit_price: float, reason: str):
        """Close an existing position"""
        if symbol in self.positions:
            position = self.positions[symbol]
            
            # Determine exit type
            exit_type = ExitType.DISCRETIONARY
            if "Stop Loss" in reason:
                exit_type = ExitType.STOP_LOSS
            elif "Target Hit" in reason:
                exit_type = ExitType.TARGET_HIT
            elif "Time Expired" in reason:
                exit_type = ExitType.TIME_EXPIRED
            
            position.close(exit_price, reason, datetime.now(), exit_type)
            
            # Move to closed positions
            self.closed_positions.append(position)
            del self.positions[symbol]
            
            # Update cash and track P&L
            self.cash += position.position_value + position.realized_pnl
            self.total_pnl += position.realized_pnl or 0
            
            # Update win/loss stats
            if position.realized_pnl and position.realized_pnl > 0:
                self.winning_trades += 1
            else:
                self.losing_trades += 1
            self.total_trades += 1
    
    def calculate_advanced_metrics(self):
        """Calculate enhanced risk-adjusted metrics"""
        if len(self.closed_positions) < 2:
            return
        
        returns = [pos.realized_pnl / pos.position_value for pos in self.closed_positions 
                  if pos.realized_pnl is not None and pos.position_value > 0]
        if not returns:
            return
        
        # Basic metrics
        self.avg_pnl = np.mean([pos.realized_pnl for pos in self.closed_positions 
                               if pos.realized_pnl is not None])
        self.success_rate = self.winning_trades / self.total_trades * 100 if self.total_trades > 0 else 0
        
        # Sortino (downside deviation)
        downside_returns = [r for r in returns if r < 0]
        downside_std = np.std(downside_returns) if downside_returns else 0.001
        self.sortino_ratio = np.mean(returns) / downside_std * np.sqrt(252) if downside_std > 0 else 0
        
        # Calmar (return/max_dd)
        self.calmar_ratio = self.total_return_pct / abs(self.max_drawdown) if self.max_drawdown < 0 else 0
        
        # Recovery factor (profit/max_dd)
        self.recovery_factor = abs(self.total_pnl / (self.initial_capital * abs(self.max_drawdown))) if self.max_drawdown < 0 else 0

@dataclass
class TeamRecommendation:
    team_id: int
    team_name: str
    symbol: str
    action: TradeAction
    confidence: float
    reasoning: str
    target_price: Optional[float]
    stop_loss: Optional[float]
    key_factors: List[str]
    timestamp: datetime = field(default_factory=datetime.now)
    recommendation_id: str = field(default_factory=lambda: f"rec_{int(time.time())}_{np.random.randint(1000)}")
    sector: Optional[str] = None

@dataclass
class VirtualPosition:
    position_id: str
    recommendation_id: str
    team_id: int
    symbol: str
    action: TradeAction
    entry_price: float
    entry_timestamp: datetime
    position_size_shares: int
    position_value: float
    confidence_at_entry: float
    reasoning: str
    key_factors: List[str]
    atr_at_entry: Optional[float]
    stop_loss: Optional[float]
    target_price: Optional[float]
    
    current_price: Optional[float] = None
    unrealized_pnl: Optional[float] = None
    realized_pnl: Optional[float] = None
    exit_price: Optional[float] = None
    exit_timestamp: Optional[datetime] = None
    exit_reason: Optional[str] = None
    status: PositionStatus = PositionStatus.OPEN
    critiqued: bool = False
    max_drawdown_pct: float = 0.0
    
    # NEW: Enhanced labeling fields
    market_regime: MarketRegime = MarketRegime.NORMAL
    exit_type: ExitType = ExitType.DISCRETIONARY
    
    def update_market_price(self, current_price: float):
        self.current_price = current_price
        if self.action in [TradeAction.BUY, TradeAction.STRONG_BUY]:
            self.unrealized_pnl = (current_price - self.entry_price) * self.position_size_shares
        else:
            self.unrealized_pnl = (self.entry_price - current_price) * self.position_size_shares
        
        # Track max drawdown
        current_value = self.position_value + (self.unrealized_pnl or 0)
        peak_value = max(self.position_value, getattr(self, 'peak_value', self.position_value))
        drawdown = (current_value - peak_value) / peak_value * 100 if peak_value > 0 else 0
        self.max_drawdown_pct = min(self.max_drawdown_pct, drawdown)
    
    def close(self, exit_price: float, reason: str, timestamp: datetime, exit_type: ExitType):
        self.exit_price = exit_price
        self.exit_timestamp = timestamp
        self.exit_reason = reason
        self.status = PositionStatus.CLOSED
        self.exit_type = exit_type
        
        if self.action in [TradeAction.BUY, TradeAction.STRONG_BUY]:
            self.realized_pnl = (exit_price - self.entry_price) * self.position_size_shares
        else:
            self.realized_pnl = (self.entry_price - exit_price) * self.position_size_shares

@dataclass
class TradeCritique:
    trade_id: str
    symbol: str
    outcome: str
    pnl_amount: float
    pnl_percentage: float
    holding_days: int
    critique_text: str
    key_factors: List[str]
    extracted_patterns: List[str]
    model_id: int
    timestamp: datetime

@dataclass
class ReviewResult:
    recommendation_id: str
    team_id: int
    symbol: str
    original_action: TradeAction
    reviewed_action: TradeAction
    original_confidence: float
    reviewed_confidence: float
    original_reasoning: str
    review_notes: str
    approved: bool
    modifications: List[str]
    risk_score: float
    outcome_predicted: str
    review_timestamp: datetime = field(default_factory=datetime.now)
    actual_outcome: Optional[str] = None
    actual_pnl_pct: Optional[float] = None
    reviewer_was_correct: Optional[bool] = None
    # NEW: Experiment tracking
    config_hash: str = ""
    rubric_version: str = ""

# ============================================================================
# MARKET REGIME DETECTOR
# ============================================================================

class MarketRegimeDetector:
    """Detect market regime for enhanced labeling"""
    
    @staticmethod
    def detect(current_price: float, hist: pd.DataFrame) -> MarketRegime:
        """
        Detect market regime based on:
        - 20-day realized volatility vs 30-day average
        - Price vs 50-day moving average (risk on/off proxy)
        """
        try:
            if len(hist) < 30:
                return MarketRegime.NORMAL
            
            # Calculate 20-day realized volatility
            returns = hist['Close'].pct_change().dropna().tail(20)
            current_vol = returns.std() * np.sqrt(252)
            avg_vol = returns.tail(30).std() * np.sqrt(252)
            
            # Calculate price vs MA50
            ma50 = hist['Close'].rolling(50).mean().iloc[-1]
            price_vs_ma = current_price / ma50
            
            # Determine regime
            if current_vol > avg_vol * 1.5:
                return MarketRegime.HIGH_VOL
            elif current_vol < avg_vol * 0.7:
                return MarketRegime.LOW_VOL
            
            if price_vs_ma > 1.05:
                return MarketRegime.RISK_ON
            elif price_vs_ma < 0.95:
                return MarketRegime.RISK_OFF
            
            return MarketRegime.NORMAL
            
        except Exception as e:
            logging.warning(f"Market regime detection failed: {e}")
            return MarketRegime.NORMAL

# ============================================================================
# PATTERN & EXIT TYPE EXTRACTOR
# ============================================================================

class PatternExtractor:
    """Extract structured trading patterns from text"""
    
    PATTERNS = [
        (r'\b(oversold|overbought)\b.*\b(rsi|stochastic|mfi)\b', 'rsi_extreme'),
        (r'\b(volume|vol)\b.*\b(spike|surge|increase)\b', 'volume_spike'),
        (r'\b(breakout|break through)\b.*\b(resistance|level)\b', 'breakout_resistance'),
        (r'\b(bounce|support)\b.*\b(level|zone)\b', 'support_bounce'),
        (r'\b(macd|moving average convergence)\b', 'macd_signal'),
        (r'\b(ma\s?\d+|sma|ema)\b.*\b(cross|golden cross|death cross)\b', 'ma_cross'),
        (r'\b(earnings|eps|revenue)\b', 'earnings_play'),
        (r'\b(dividend|yield|payout)\b', 'dividend_play'),
        (r'\b(valuation|undervalued|overvalued|pe ratio|pb ratio)\b', 'valuation_play'),
        (r'\b(momentum|trend|continuation)\b', 'momentum_continuation'),
        (r'\b(reversal|mean reversion|revert)\b', 'mean_reversion'),
        (r'\b(consolidation|sideways|range)\b', 'range_bound')
    ]
    
    @staticmethod
    def extract(text: str) -> List[str]:
        """Extract patterns from text"""
        import re
        
        text_lower = text.lower()
        found_patterns = []
        
        for pattern_regex, pattern_name in PatternExtractor.PATTERNS:
            if re.search(pattern_regex, text_lower, re.IGNORECASE):
                found_patterns.append(pattern_name)
        
        return list(set(found_patterns))[:5]

# ============================================================================
# CONFIGURATION
# ============================================================================

@dataclass
class TournamentConfig:
    """Configuration with experiment tracking"""
    
    # API KEYS - KIMI API KEY ADDED
    ANTHROPIC_API_KEY: str = field(default_factory=lambda: os.environ.get('ANTHROPIC_API_KEY', ''))
    KIMI_API_KEY: str = field(default_factory=lambda: os.environ.get('KIMI_API_KEY', ''))  # NEW
    DEEPSEEK_API_KEY: str = field(default_factory=lambda: os.environ.get('DEEPSEEK_API_KEY', ''))
    GOOGLE_API_KEY: str = field(default_factory=lambda: os.environ.get('GOOGLE_API_KEY', ''))
    
    # WATCHLIST
    WATCHLIST: List[str] = field(default_factory=lambda: [
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'AMD', 'INTC', 'AVGO',
        'ORCL', 'CRM', 'ADBE', 'CSCO', 'ACN', 'IBM', 'TXN', 'QCOM', 'AMAT', 'ADI',
        'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'USB', 'PNC', 'TFC', 'COF',
        'UNH', 'JNJ', 'PFE', 'ABT', 'TMO', 'MRK', 'LLY', 'ABBV', 'BMY', 'AMGN',
        'WMT', 'HD', 'NKE', 'MCD', 'SBUX', 'DIS', 'NFLX', 'CMCSA', 'COST', 'TGT',
        'BA', 'CAT', 'GE', 'MMM', 'HON', 'UNP', 'UPS', 'RTX', 'LMT', 'DE'
    ])
    
    # VIRTUAL PORTFOLIO SETTINGS
    INITIAL_VIRTUAL_CAPITAL: float = 100_000.0
    MAX_POSITION_SIZE_PCT: float = 10.0
    DAILY_RISK_LIMIT_PCT: float = 2.0
    MAX_POSITIONS: int = 15
    
    # AI TEAM CONFIGURATION
    ACTIVE_TEAMS: List[int] = field(default_factory=lambda: [1, 2, 3, 4])
    
    # FILTERING SETTINGS
    FILTER_MIN_SCORE: float = 40.0
    MAX_DAILY_SCREENING: int = 100
    MAX_DAILY_ANALYSIS: int = 8
    
    # COST SETTINGS
    SCREENING_COST: float = 0.0005
    TEAM_COSTS: Dict[int, float] = field(default_factory=lambda: {
        1: 0.075, 2: 0.0027, 3: 0.030, 4: 0.020  # Team 3 cost is for Kimi
    })
    
    # RISK PARAMETERS
    KELLY_MULTIPLIER: float = 0.25
    STOP_LOSS_ATR_MULTIPLIER: float = 2.0
    TAKE_PROFIT_ATR_MULTIPLIER: float = 3.0
    
    # TECHNICAL INDICATORS
    PRICE_MOVE_THRESHOLD: float = 2.0
    VOLUME_SPIKE_THRESHOLD: float = 1.5
    RSI_OVERSOLD: float = 30.0
    RSI_OVERBOUGHT: float = 70.0
    
    # SYSTEM
    DB_FILE: str = "ultimate_tournament.db"
    LOG_FILE: str = "ultimate_tournament.log"
    LOG_LEVEL: str = "INFO"
    VECTOR_DB_PATH: str = "./vector_memory"
    
    # TOURNAMENT DURATION
    TOURNAMENT_DAYS: int = 90
    
    # LEARNING SETTINGS
    MAX_MEMORIES_PER_PROMPT: int = 5
    META_CRITIQUE_INTERVAL: int = 10
    REVIEWER_CALIBRATION_DAY: int = 4  # Friday
    
    # Experiment tracking
    EXPERIMENT_ID: str = field(default_factory=lambda: f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    RUBRIC_VERSION: str = "1.0"
    CONFIG_HASH: str = field(default_factory=lambda: hashlib.md5(open(__file__).read().encode()).hexdigest()[:12])

# ============================================================================
# SMART FILTERING
# ============================================================================

class SmartFilter:
    """3-tier stock filtering with regime detection"""
    
    def __init__(self, config: TournamentConfig):
        self.cfg = config
        self.logger = logging.getLogger("Filter")
        self.regime_detector = MarketRegimeDetector()
    
    def tier1_technical_screen(self, watchlist: List[str]) -> List[FilterResult]:
        """Tier 1: Technical screen with regime tagging"""
        print(f"\nüîç TIER 1: Technical Screen ({len(watchlist)} stocks)")
        print("‚îÄ" * 85)
        
        results = []
        for i, symbol in enumerate(watchlist, 1):
            if i % 20 == 0:
                print(f"  Progress: {i}/{len(watchlist)}...", end='\r', flush=True)
            
            try:
                stock = yf.Ticker(symbol)
                hist = stock.history(period='3mo')
                
                if hist.empty or len(hist) < 50:
                    continue
                
                current = hist['Close'].iloc[-1]
                change_1d = (current - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2] * 100
                
                if len(hist) >= 6:
                    change_5d = (current - hist['Close'].iloc[-6]) / hist['Close'].iloc[-6] * 100
                else:
                    change_5d = 0
                
                avg_volume = hist['Volume'].iloc[-21:-1].mean()
                volume_ratio = hist['Volume'].iloc[-1] / avg_volume if avg_volume > 0 else 1
                
                delta = hist['Close'].diff()
                gain = delta.where(delta > 0, 0).rolling(14).mean()
                loss = -delta.where(delta < 0, 0).rolling(14).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs.iloc[-1]))
                
                ma50 = hist['Close'].rolling(50).mean().iloc[-1]
                ma200 = hist['Close'].rolling(200).mean().iloc[-1] if len(hist) >= 200 else current
                
                tr = pd.concat([
                    hist['High'] - hist['Low'],
                    abs(hist['High'] - hist['Close'].shift(1)),
                    abs(hist['Low'] - hist['Close'].shift(1))
                ], axis=1).max(axis=1)
                atr14 = tr.rolling(14).mean().iloc[-1]
                
                info = stock.info
                market_cap = info.get('marketCap', 0)
                
                # Detect market regime
                regime = self.regime_detector.detect(current, hist)
                
                # Scoring
                score = 0
                signals = []
                
                if abs(change_1d) >= self.cfg.PRICE_MOVE_THRESHOLD:
                    score += 25
                    signals.append(f"Price {change_1d:+.1f}%")
                
                if volume_ratio >= self.cfg.VOLUME_SPIKE_THRESHOLD:
                    score += 20
                    signals.append(f"Volume {volume_ratio:.1f}x")
                
                if rsi <= self.cfg.RSI_OVERSOLD:
                    score += 15
                    signals.append(f"RSI oversold ({rsi:.0f})")
                elif rsi >= self.cfg.RSI_OVERBOUGHT:
                    score += 15
                    signals.append(f"RSI overbought ({rsi:.0f})")
                
                if current > ma50 and current > ma200:
                    score += 10
                    signals.append("Above MAs")
                
                high_52w = hist['High'].max()
                if current >= high_52w * 0.98:
                    score += 20
                    signals.append("Near 52w high")
                
                if score >= self.cfg.FILTER_MIN_SCORE:
                    results.append(FilterResult(
                        symbol=symbol,
                        score=score,
                        signals=signals,
                        stock_data=StockData(
                            symbol=symbol,
                            price=current,
                            change_1d=change_1d,
                            change_5d=change_5d,
                            volume_ratio=volume_ratio,
                            rsi=rsi,
                            above_ma50=current > ma50,
                            above_ma200=current > ma200,
                            market_cap=market_cap,
                            atr=atr14,
                            sector=info.get('sector', 'unknown')
                        ),
                        priority=1 if score >= 70 else 2 if score >= 55 else 3
                    ))
            
            except Exception as e:
                continue
        
        results.sort(key=lambda x: x.score, reverse=True)
        print(f"\n  ‚úÖ {len(results)} stocks passed (Score ‚â• {self.cfg.FILTER_MIN_SCORE})")
        return results

# ============================================================================
# VECTOR MEMORY SYSTEM
# ============================================================================

class VectorMemoryStore:
    """Chromadb-based vector memory with enhanced metadata"""
    
    def __init__(self, config: TournamentConfig):
        self.cfg = config
        self.client = chromadb.PersistentClient(path=config.VECTOR_DB_PATH)
        
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"
        )
        
        self.collections = {}
    
    def get_or_create_collection(self, model_id: int):
        if model_id not in self.collections:
            collection_name = f"model_{model_id}_critiques"
            try:
                self.collections[model_id] = self.client.get_collection(
                    name=collection_name,
                    embedding_function=self.embedding_fn
                )
            except Exception:
                self.collections[model_id] = self.client.create_collection(
                    name=collection_name,
                    embedding_function=self.embedding_fn
                )
        return self.collections[model_id]
    
    def store_critique(self, critique: TradeCritique, regime: MarketRegime, exit_type: ExitType) -> str:
        """Store critique with regime and exit type for enhanced filtering"""
        collection = self.get_or_create_collection(critique.model_id)
        
        doc = f"""
Trade: {critique.symbol}
Outcome: {critique.outcome.upper()}
P&L: ${critique.pnl_amount:+.2f} ({critique.pnl_percentage:+.1f}%)
Holding Days: {critique.holding_days}
Key Factors: {', '.join(critique.key_factors)}
Patterns: {', '.join(critique.extracted_patterns)}

Critique: {critique.critique_text}
"""
        
        trade_hash = hashlib.md5(
            f"{critique.trade_id}_{critique.timestamp.isoformat()}".encode()
        ).hexdigest()[:12]
        
        try:
            collection.add(
                documents=[doc],
                metadatas=[{
                    "symbol": critique.symbol,
                    "outcome": critique.outcome,
                    "pnl_amount": critique.pnl_amount,
                    "pnl_percentage": critique.pnl_percentage,
                    "holding_days": critique.holding_days,
                    "key_factors": json.dumps(critique.key_factors),
                    "patterns": json.dumps(critique.extracted_patterns),
                    "timestamp": critique.timestamp.isoformat(),
                    "model_id": critique.model_id,
                    "trade_quality": self._label_quality(critique.pnl_percentage),
                    "market_regime": regime.value,  # NEW
                    "exit_type": exit_type.value    # NEW
                }],
                ids=[trade_hash]
            )
        except Exception as e:
            logging.error(f"Failed to store critique: {e}")
            return None
        
        return trade_hash
    
    def _label_quality(self, pnl_pct: float) -> str:
        if pnl_pct > 10:
            return "EXCELLENT"
        elif pnl_pct > 5:
            return "GOOD"
        elif pnl_pct > -2:
            return "NEUTRAL"
        elif pnl_pct > -8:
            return "POOR"
        else:
            return "TERRIBLE"
    
    def get_relevant_memories(self, model_id: int, symbol: str, 
                            current_factors: List[str], patterns: List[str],
                            regime: MarketRegime, n_results: int = 5) -> List[Dict]:
        """Retrieve memories filtered by regime and patterns"""
        collection = self.get_or_create_collection(model_id)
        
        if collection.count() == 0:
            return []
        
        query_text = f"""
        Trade: {symbol}
        Key Factors: {', '.join(current_factors)}
        Patterns: {', '.join(patterns)}
        """
        
        try:
            # Filter by regime and patterns for better relevance
            where_filter = {
                "$and": [
                    {"market_regime": regime.value},
                    {"$or": [{"patterns": {"$contains": pattern}} for pattern in patterns[:2]]}
                ]
            } if patterns else {"market_regime": regime.value}
            
            results = collection.query(
                query_texts=[query_text],
                n_results=min(n_results, collection.count()),
                where=where_filter,
                include=["documents", "metadatas", "distances"]
            )
            
            if not results['documents'][0]:
                return []
            
            memories = []
            for i in range(len(results['documents'][0])):
                memories.append({
                    'document': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i]
                })
            
            return memories
        except Exception as e:
            logging.error(f"Failed to retrieve memories: {e}")
            return []

# ============================================================================
# TOURNAMENT META-MEMORY
# ============================================================================

class TournamentMemory:
    """Cross-team memory with pattern tracking"""
    
    def __init__(self):
        self.team_performance = defaultdict(lambda: {
            'trades': [],
            'last_10_pnls': [],
            'strategies': defaultdict(int),
            'symbols': defaultdict(int),
            'patterns': defaultdict(int)
        })
        self.market_regimes = []
        self.performance_snapshots = []
    
    def record_trade(self, team_id: int, symbol: str, pnl_pct: float, 
                    key_factors: List[str], patterns: List[str], outcome: str):
        perf = self.team_performance[team_id]
        perf['trades'].append(pnl_pct)
        perf['last_10_pnls'].append(pnl_pct)
        
        if len(perf['last_10_pnls']) > 10:
            perf['last_10_pnls'].pop(0)
        
        for factor in key_factors:
            perf['strategies'][factor] += 1 if pnl_pct > 0 else -1
        
        for pattern in patterns:
            perf['patterns'][pattern] += 1 if pnl_pct > 0 else -1
        
        perf['symbols'][symbol] += 1 if pnl_pct > 0 else -1
    
    def get_tournament_state(self) -> Dict[str, Any]:
        rankings = {}
        team_stats = {}
        leader_id = None
        top_return = -999
        
        for team_id, perf in self.team_performance.items():
            if not perf['trades']:
                continue
            
            total_return = sum(perf['trades'])
            recent_avg = sum(perf['last_10_pnls']) / len(perf['last_10_pnls']) if perf['last_10_pnls'] else 0
            rankings[team_id] = total_return
            
            team_stats[team_id] = {
                'team_id': team_id,
                'total_return_pct': total_return,
                'recent_avg_pnl': recent_avg,
                'total_trades': len(perf['trades']),
                'win_rate': sum(1 for p in perf['trades'] if p > 0) / len(perf['trades']) * 100
            }
            
            if total_return > top_return:
                top_return = total_return
                leader_id = team_id
        
        sorted_teams = sorted(rankings.items(), key=lambda x: x[1], reverse=True)
        team_rankings = {team_id: rank+1 for rank, (team_id, _) in enumerate(sorted_teams)}
        
        top_strategies = {}
        for team_id, perf in self.team_performance.items():
            if perf['strategies']:
                factors = sorted(perf['strategies'].items(), key=lambda x: x[1], reverse=True)[:2]
                patterns = sorted(perf['patterns'].items(), key=lambda x: x[1], reverse=True)[:2]
                top_strategies[team_id] = {
                    'factors': [f for f, score in factors if score > 0],
                    'patterns': [p for p, score in patterns if score > 0]
                }
        
        symbol_performance = defaultdict(int)
        for team_id, perf in self.team_performance.items():
            for symbol, score in perf['symbols'].items():
                symbol_performance[symbol] += score
        
        hot_symbols = sorted(symbol_performance.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            'leader_id': leader_id,
            'rankings': team_rankings,
            'teams': team_stats,
            'top_performers': top_strategies,
            'hot_symbols': [s for s, _ in hot_symbols if _ > 0]
        }

# ============================================================================
# AI TEAM BASE CLASS
# ============================================================================

class AI_Team_Base:
    """Base class with pattern extraction and memory"""
    
    def __init__(self, config: TournamentConfig, memory_store: VectorMemoryStore,
                 tournament_memory: TournamentMemory):
        self.cfg = config
        self.memory_store = memory_store
        self.tournament_memory = tournament_memory
        self.team_id: int = 0
        self.team_name: str = ""
        self.logger = logging.getLogger(self.team_name)
        self.performance_history = []
        self.success_rate = 0.0
        self.avg_pnl = 0.0
        self.total_trades = 0
        self.pattern_extractor = PatternExtractor()
        self.cross_team_patterns = []  # Filled by orchestrator
    
    def update_performance_stats(self):
        if len(self.performance_history) < 3:
            return
        
        recent = self.performance_history[-20:]
        wins = [t for t in recent if t['pnl'] > 0]
        
        self.success_rate = len(wins) / len(recent) * 100 if recent else 0
        self.avg_pnl = sum(t['pnl'] for t in recent) / len(recent) if recent else 0
        self.total_trades = len(self.performance_history)
    
    def get_relevant_memories_prompt(self, symbol: str, key_factors: List[str], 
                                   patterns: List[str], regime: MarketRegime) -> str:
        memories = self.memory_store.get_relevant_memories(
            self.team_id, symbol, key_factors, patterns, regime
        )
        
        if not memories:
            return ""
        
        prompt = "\n\nüìö RELEVANT PAST TRADES (Learn from history):\n"
        prompt += "‚îÄ" * 60 + "\n"
        
        for i, mem in enumerate(memories[:self.cfg.MAX_MEMORIES_PER_PROMPT], 1):
            meta = mem['metadata']
            prompt += f"""
Trade {i}: {meta['symbol']} | {meta['outcome'].upper()} | {float(meta['pnl_percentage']):+.1f}%
Quality: {meta.get('trade_quality', 'unknown')}
Regime: {meta.get('market_regime', 'unknown')}
Exit: {meta.get('exit_type', 'unknown')}
Factors: {', '.join(json.loads(meta['key_factors']))}
Patterns: {', '.join(json.loads(meta.get('patterns', '[]')))}
Lesson: {mem['document'].split('Critique:')[1][:120]}...
"""
        
        prompt += "\nüí° How does this inform your current decision?\n"
        return prompt
    
    def self_critique(self, position: VirtualPosition, regime: MarketRegime) -> Optional[TradeCritique]:
        profit_loss = "profit" if position.realized_pnl > 0 else "loss"
        pnl_pct = (position.realized_pnl / position.position_value) * 100 if position.position_value > 0 else 0
        holding_days = (position.exit_timestamp - position.entry_timestamp).days if position.exit_timestamp else 0
        
        prompt = f"""You just closed a trade with a {profit_loss}.

TRADE SUMMARY:
- Symbol: {position.symbol}
- Action: {position.action.value}
- Entry: ${position.entry_price:.2f}
- Exit: ${position.exit_price:.2f}
- P&L: ${position.realized_pnl:+.2f} ({pnl_pct:+.1f}%)
- Holding: {holding_days} days
- Initial Confidence: {position.confidence_at_entry}%
- Key Factors: {', '.join(position.key_factors)}
- Max Drawdown: {position.max_drawdown_pct:.1f}%
- Market Regime: {regime.value}
- Exit Type: {position.exit_type.value}

ANALYZE:
1. What went {"right" if profit_loss == "profit" else "wrong"}?
2. Which factors/patterns were predictive vs misleading?
3. What would you do differently?
4. Should this exit type be used more/less?

Provide a concise 3-4 sentence critique focusing on actionable insights."""

        try:
            critique_text = self._call_ai_for_critique(prompt)
            patterns = self.pattern_extractor.extract(critique_text)
            
            critique = TradeCritique(
                trade_id=position.position_id,
                symbol=position.symbol,
                outcome=profit_loss,
                pnl_amount=position.realized_pnl,
                pnl_percentage=pnl_pct,
                holding_days=holding_days,
                critique_text=critique_text,
                key_factors=position.key_factors,
                extracted_patterns=patterns,
                model_id=self.team_id,
                timestamp=datetime.now()
            )
            
            # Store with regime and exit type
            self.memory_store.store_critique(critique, regime, position.exit_type)
            
            self.performance_history.append({
                'symbol': position.symbol,
                'pnl': position.realized_pnl,
                'pnl_pct': pnl_pct,
                'outcome': profit_loss,
                'holding_days': holding_days,
                'key_factors': position.key_factors,
                'patterns': patterns
            })
            
            self.update_performance_stats()
            
            self.tournament_memory.record_trade(
                self.team_id, position.symbol, pnl_pct, 
                position.key_factors, patterns, profit_loss
            )
            
            return critique
            
        except Exception as e:
            self.logger.error(f"Self-critique failed: {e}")
            return None
    
    def _call_ai_for_critique(self, prompt: str) -> str:
        raise NotImplementedError
    
    def create_recommendation(self, stock: FilterResult, portfolio: VirtualPortfolio,
                             tournament_state: Dict = None) -> Optional['TeamRecommendation']:
        raise NotImplementedError

# ============================================================================
# ENHANCED AI TEAMS - KIMI INTEGRATION
# ============================================================================

class AI_Team_Claude(AI_Team_Base):
    """Team 1: Claude with pattern-aware memory"""
    
    def __init__(self, config: TournamentConfig, memory_store: VectorMemoryStore,
                 tournament_memory: TournamentMemory):
        super().__init__(config, memory_store, tournament_memory)
        self.cfg = config
        self.client = Anthropic(api_key=config.ANTHROPIC_API_KEY)
        self.team_id = 1
        self.team_name = "Claude Opus (Pattern-Aware)"
        self.logger = logging.getLogger(self.team_name)
    
    def _call_ai_for_critique(self, prompt: str) -> str:
        response = self.client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=800,
            temperature=0.2,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    
    def create_recommendation(self, stock: FilterResult, portfolio: VirtualPortfolio,
                             tournament_state: Dict = None) -> Optional['TeamRecommendation']:
        patterns = self.pattern_extractor.extract(' '.join(stock.signals))
        regime = portfolio.current_regime
        
        memory_prompt = self.get_relevant_memories_prompt(stock.symbol, stock.signals, patterns, regime)
        
        awareness_prompt = ""
        if tournament_state and len(tournament_state.get('teams', [])) > 1:
            awareness_prompt = "\n\nüë• TOURNAMENT INTELLIGENCE:\n"
            awareness_prompt += "‚îÄ" * 60 + "\n"
            
            my_rank = tournament_state['rankings'].get(self.team_id, 0)
            if my_rank > 1:
                leader_id = tournament_state['leader_id']
                if leader_id and leader_id in tournament_state['teams']:
                    leader = tournament_state['teams'][leader_id]
                    awareness_prompt += f"You are ranked #{my_rank}. Leader has {leader['total_return_pct']:+.1f}% vs your {portfolio.total_return_pct:+.1f}%.\n"
                    awareness_prompt += f"Top patterns used by leaders: {leader.get('patterns', [])[:2]}\n"
            else:
                awareness_prompt += f"You are ranked #1! Maintain discipline.\n"
            
            if self.cross_team_patterns:
                awareness_prompt += f"\nCross-team patterns working: {[p['pattern'] for p in self.cross_team_patterns[:2]]}\n"
            
            if tournament_state['hot_symbols']:
                awareness_prompt += f"\nHot symbols: {tournament_state['hot_symbols']}\n"
        
        prompt = f"""You are {self.team_name} managing a virtual portfolio with ${portfolio.total_value:,.2f} equity.

CURRENT PORTFOLIO:
- Cash: ${portfolio.cash:,.2f}
- Open Positions: {len(portfolio.positions)}
- Today's P&L: ${portfolio.daily_pnl:+.2f}
- Max Drawdown: {portfolio.max_drawdown:.1f}%
- Recent Success Rate: {self.success_rate:.1f}%
- Avg P&L: ${self.avg_pnl:+.2f}

ANALYZE: {stock.symbol}
Price: ${stock.stock_data.price:.2f}
Change: {stock.stock_data.change_1d:+.1f}%
Volume: {stock.stock_data.volume_ratio:.1f}x
RSI: {stock.stock_data.rsi:.0f}
Score: {stock.score}/100
Signals: {', '.join(stock.signals[:3])}
ATR: ${stock.stock_data.atr:.2f}
Sector: {stock.stock_data.sector}
Regime: {regime.value}

{memory_prompt}{awareness_prompt}

RULES:
- Risk max 2% of equity per trade
- Max 10% in any single position
- No leverage (cash only)
- Learn from past patterns above

JSON output:
{{
    "action": "BUY|SELL|HOLD|STRONG_BUY|STRONG_SELL",
    "confidence": 50-100,
    "reasoning": "3-5 sentences",
    "target_price": number,
    "stop_loss": number,
    "key_factors": ["factor1", "factor2", "factor3"]
}}"""

        try:
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1500,
                temperature=0.25,
                messages=[{"role": "user", "content": prompt}]
            )
            
            content = response.content[0].text
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            result = json.loads(content.strip())
            
            return TeamRecommendation(
                team_id=self.team_id,
                team_name=self.team_name,
                symbol=stock.symbol,
                action=TradeAction[result['action']],
                confidence=result['confidence'],
                reasoning=result['reasoning'],
                target_price=result.get('target_price'),
                stop_loss=result.get('stop_loss'),
                key_factors=result.get('key_factors', []),
                sector=stock.stock_data.sector
            )
        
        except Exception as e:
            self.logger.error(f"Recommendation failed: {e}")
            return None

class AI_Team_DeepSeek(AI_Team_Base):
    def __init__(self, config: TournamentConfig, memory_store: VectorMemoryStore,
                 tournament_memory: TournamentMemory):
        super().__init__(config, memory_store, tournament_memory)
        self.cfg = config
        self.client = OpenAI(api_key=config.DEEPSEEK_API_KEY, base_url="https://api.deepseek.com/v1")
        self.team_id = 2
        self.team_name = "DeepSeek-V3 (Pattern-Aware)"
        self.logger = logging.getLogger(self.team_name)
    
    def _call_ai_for_critique(self, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.25,
            max_tokens=800
        )
        return response.choices[0].message.content
    
    def create_recommendation(self, stock: FilterResult, portfolio: VirtualPortfolio,
                             tournament_state: Dict = None) -> Optional['TeamRecommendation']:
        patterns = self.pattern_extractor.extract(' '.join(stock.signals))
        regime = portfolio.current_regime
        
        memory_prompt = self.get_relevant_memories_prompt(stock.symbol, stock.signals, patterns, regime)
        
        prompt = f"""Portfolio: ${portfolio.total_value:,.2f} | Open: {len(portfolio.positions)}
Stock: {stock.symbol} @ ${stock.stock_data.price:.2f}
RSI: {stock.stock_data.rsi:.0f}, Vol: {stock.stock_data.volume_ratio:.1f}x
Score: {stock.score}/100, ATR: ${stock.stock_data.atr:.2f}

{memory_prompt}

JSON: {{"action":"BUY|SELL","confidence":0-100,"reasoning":"...","target":price,"stop":price,"factors":["..."]}}"""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.25,
                max_tokens=1200
            )
            
            content = response.choices[0].message.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            
            result = json.loads(content.strip())
            
            return TeamRecommendation(
                team_id=self.team_id,
                team_name=self.team_name,
                symbol=stock.symbol,
                action=TradeAction[result['action']],
                confidence=result['confidence'],
                reasoning=result['reasoning'],
                target_price=result.get('target'),
                stop_loss=result.get('stop'),
                key_factors=result.get('factors', []),
                sector=stock.stock_data.sector
            )
        
        except Exception as e:
            self.logger.error(f"Recommendation failed: {e}")
            return None

# KIMI AI TEAM - REPLACES GPT-4o
class AI_Team_Kimi(AI_Team_Base):
    """Team 3: Kimi by Moonshot AI (Pattern-Aware)"""
    
    def __init__(self, config: TournamentConfig, memory_store: VectorMemoryStore,
                 tournament_memory: TournamentMemory):
        super().__init__(config, memory_store, tournament_memory)
        self.cfg = config
        # Kimi API is OpenAI-compatible - just change base_url
        self.client = OpenAI(
            api_key=config.KIMI_API_KEY,
            base_url="https://api.moonshot.cn/v1"
        )
        self.team_id = 3
        self.team_name = "Kimi (Moonshot AI) Pattern-Aware"
        self.logger = logging.getLogger(self.team_name)
    
    def _call_ai_for_critique(self, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model="moonshot-v1-8k",  # Kimi model
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        return response.choices[0].message.content
    
    def create_recommendation(self, stock: FilterResult, portfolio: VirtualPortfolio,
                             tournament_state: Dict = None) -> Optional['TeamRecommendation']:
        patterns = self.pattern_extractor.extract(' '.join(stock.signals))
        regime = portfolio.current_regime
        
        memory_prompt = self.get_relevant_memories_prompt(stock.symbol, stock.signals, patterns, regime)
        
        prompt = f"""Portfolio Value: ${portfolio.total_value:,.2f}
Cash: ${portfolio.cash:,.2f}
Open Positions: {len(portfolio.positions)}

Analyze: {stock.symbol}
Price: ${stock.stock_data.price:.2f}
ATR: ${stock.stock_data.atr:.2f}

{memory_prompt}

JSON: {{"action":"BUY|SELL","confidence":0-100,"reasoning":"...","target":price,"stop":price,"factors":["..."]}}"""

        try:
            response = self.client.chat.completions.create(
                model="moonshot-v1-8k",  # Use Kimi model
                messages=[{"role": "user", "content": prompt}],
                temperature=0.25,
                max_tokens=1200
            )
            
            content = response.choices[0].message.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            
            result = json.loads(content.strip())
            
            return TeamRecommendation(
                team_id=self.team_id,
                team_name=self.team_name,
                symbol=stock.symbol,
                action=TradeAction[result['action']],
                confidence=result['confidence'],
                reasoning=result['reasoning'],
                target_price=result.get('target'),
                stop_loss=result.get('stop'),
                key_factors=result.get('factors', []),
                sector=stock.stock_data.sector
            )
        
        except Exception as e:
            self.logger.error(f"Recommendation failed: {e}")
            return None

class AI_Team_Gemini(AI_Team_Base):
    def __init__(self, config: TournamentConfig, memory_store: VectorMemoryStore,
                 tournament_memory: TournamentMemory):
        super().__init__(config, memory_store, tournament_memory)
        self.cfg = config
        self.team_id = 4
        self.team_name = "Gemini 2.0 Flash (Pattern-Aware)"
        self.logger = logging.getLogger(self.team_name)
        
        try:
            genai.configure(api_key=config.GOOGLE_API_KEY)
            self.model = genai.GenerativeModel("gemini-2.0-flash-thinking-exp")
            self.available = True
        except:
            self.available = False
    
    def _call_ai_for_critique(self, prompt: str) -> str:
        response = self.model.generate_content(
            prompt,
            generation_config={'temperature': 0.2, 'max_output_tokens': 800}
        )
        return response.text
    
    def create_recommendation(self, stock: FilterResult, portfolio: VirtualPortfolio,
                             tournament_state: Dict = None) -> Optional['TeamRecommendation']:
        if not self.available:
            return None
        
        patterns = self.pattern_extractor.extract(' '.join(stock.signals))
        regime = portfolio.current_regime
        
        memory_prompt = self.get_relevant_memories_prompt(stock.symbol, stock.signals, patterns, regime)
        
        prompt = f"""Portfolio: ${portfolio.total_value:,.2f} | Open: {len(portfolio.positions)}
Stock: {stock.symbol} @ ${stock.stock_data.price:.2f}

{memory_prompt}

JSON: {{"action":"BUY|SELL","confidence":0-100,"reasoning":"...","target":price,"stop":price}}"""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config={'temperature': 0.25, 'max_output_tokens': 1200}
            )
            
            content = response.text
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            
            result = json.loads(content.strip())
            
            return TeamRecommendation(
                team_id=self.team_id,
                team_name=self.team_name,
                symbol=stock.symbol,
                action=TradeAction[result['action']],
                confidence=result['confidence'],
                reasoning=result['reasoning'],
                target_price=result.get('target'),
                stop_loss=result.get('stop'),
                key_factors=result.get('key_factors', []),
                sector=stock.stock_data.sector
            )
        
        except Exception as e:
            self.logger.error(f"Recommendation failed: {e}")
            return None

# ============================================================================
# ENHANCED DATABASE WITH EXPERIMENT TRACKING
# ============================================================================

class EnhancedTournamentDatabase:
    """Database with experiment tracking and enhanced labeling"""
    
    def __init__(self, config: TournamentConfig):
        self.cfg = config
        self.db_file = Path(config.DB_FILE)
        self.init_database()
    
    def init_database(self):
        """Initialize all tables with experiment tracking fields"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        # Recommendations table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS recommendations (
            recommendation_id TEXT PRIMARY KEY,
            experiment_id TEXT NOT NULL,
            config_hash TEXT NOT NULL,
            team_id INTEGER NOT NULL,
            symbol TEXT NOT NULL,
            action TEXT NOT NULL,
            confidence REAL,
            reasoning TEXT,
            key_factors TEXT,
            patterns TEXT,
            technical_score REAL,
            atr REAL,
            sector TEXT,
            timestamp TIMESTAMP,
            executed INTEGER DEFAULT 0
        )
        """)
        
        # Positions table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS positions (
            position_id TEXT PRIMARY KEY,
            recommendation_id TEXT NOT NULL,
            experiment_id TEXT NOT NULL,
            config_hash TEXT NOT NULL,
            team_id INTEGER NOT NULL,
            symbol TEXT NOT NULL,
            action TEXT NOT NULL,
            entry_timestamp TIMESTAMP NOT NULL,
            entry_price REAL NOT NULL,
            position_size_shares INTEGER NOT NULL,
            position_value REAL NOT NULL,
            stop_loss REAL,
            target_price REAL,
            atr_at_entry REAL,
            confidence_at_entry REAL,
            reasoning TEXT,
            key_factors TEXT,
            patterns TEXT,
            market_regime TEXT NOT NULL,
            status TEXT DEFAULT 'OPEN',
            max_drawdown_pct REAL DEFAULT 0,
            critiqued INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (recommendation_id) REFERENCES recommendations(recommendation_id)
        )
        """)
        
        # Review decisions table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS review_decisions (
            review_id TEXT PRIMARY KEY,
            recommendation_id TEXT NOT NULL,
            experiment_id TEXT NOT NULL,
            config_hash TEXT NOT NULL,
            rubric_version TEXT NOT NULL,
            team_id INTEGER NOT NULL,
            symbol TEXT NOT NULL,
            original_action TEXT NOT NULL,
            reviewed_action TEXT NOT NULL,
            original_confidence REAL,
            reviewed_confidence REAL,
            risk_score REAL,
            outcome_predicted TEXT,
            approved INTEGER,
            modifications TEXT,
            review_notes TEXT,
            review_timestamp TIMESTAMP,
            actual_outcome TEXT,
            actual_pnl_pct REAL,
            reviewer_was_correct INTEGER,
            FOREIGN KEY (recommendation_id) REFERENCES recommendations(recommendation_id)
        )
        """)
        
        # Portfolio snapshots
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS portfolio_snapshots (
            snapshot_date DATE NOT NULL,
            experiment_id TEXT NOT NULL,
            config_hash TEXT NOT NULL,
            team_id INTEGER NOT NULL,
            total_value REAL NOT NULL,
            cash REAL NOT NULL,
            total_return_pct REAL NOT NULL,
            max_drawdown REAL,
            sharpe_ratio REAL,
            sortino_ratio REAL,
            calmar_ratio REAL,
            recovery_factor REAL,
            winning_trades INTEGER,
            losing_trades INTEGER,
            total_trades INTEGER,
            api_costs REAL,
            success_rate REAL,
            avg_pnl REAL,
            PRIMARY KEY (snapshot_date, team_id, experiment_id)
        )
        """)
        
        # Daily P&L
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS daily_pnl (
            date DATE NOT NULL,
            experiment_id TEXT NOT NULL,
            team_id INTEGER NOT NULL,
            daily_pnl REAL NOT NULL,
            daily_return_pct REAL NOT NULL,
            PRIMARY KEY (date, team_id, experiment_id)
        )
        """)
        
        # Experiments log
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS experiments (
            experiment_id TEXT PRIMARY KEY,
            config_hash TEXT NOT NULL,
            rubric_version TEXT NOT NULL,
            start_date TIMESTAMP,
            end_date TIMESTAMP,
            description TEXT
        )
        """)
        
        conn.commit()
        conn.close()
        print(f"‚úÖ Database initialized: {self.db_file}")
    
    def save_recommendation(self, rec: TeamRecommendation, stock: FilterResult, 
                          config: TournamentConfig) -> str:
        """Save recommendation with experiment tracking"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        cursor = conn.cursor()
        
        patterns = PatternExtractor.extract(rec.reasoning)
        
        cursor.execute("""
        INSERT INTO recommendations (
            recommendation_id, experiment_id, config_hash, team_id, symbol, action, confidence, reasoning,
            key_factors, patterns, technical_score, atr, sector, timestamp
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            rec.recommendation_id, config.EXPERIMENT_ID, config.CONFIG_HASH, rec.team_id, rec.symbol,
            rec.action.value, rec.confidence, rec.reasoning, json.dumps(rec.key_factors),
            json.dumps(patterns), stock.score, stock.stock_data.atr, rec.sector, datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
        return rec.recommendation_id
    
    def save_position(self, pos: VirtualPosition, config: TournamentConfig):
        """Save position with regime and experiment tracking"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("""
        INSERT OR REPLACE INTO positions (
            position_id, recommendation_id, experiment_id, config_hash, team_id, symbol, action, entry_timestamp, entry_price,
            position_size_shares, position_value, stop_loss, target_price, atr_at_entry, confidence_at_entry,
            reasoning, key_factors, patterns, market_regime, status, max_drawdown_pct, critiqued, created_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            pos.position_id, pos.recommendation_id, self.cfg.EXPERIMENT_ID, self.cfg.CONFIG_HASH,
            pos.team_id, pos.symbol, pos.action.value, pos.entry_timestamp.isoformat(), pos.entry_price,
            pos.position_size_shares, pos.position_value, pos.stop_loss, pos.target_price,
            pos.atr_at_entry, pos.confidence_at_entry, pos.reasoning, json.dumps(pos.key_factors),
            json.dumps([]), pos.market_regime.value, pos.status.value, pos.max_drawdown_pct,
            int(pos.critiqued), datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    def save_review_result(self, review: ReviewResult, config: TournamentConfig):
        """Save review decision with experiment tracking"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("""
        INSERT OR REPLACE INTO review_decisions (
            review_id, recommendation_id, experiment_id, config_hash, rubric_version, team_id, symbol, original_action,
            reviewed_action, original_confidence, reviewed_confidence, risk_score, outcome_predicted, approved,
            modifications, review_notes, review_timestamp, actual_outcome, actual_pnl_pct, reviewer_was_correct
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            f"{review.recommendation_id}_review", review.recommendation_id, config.EXPERIMENT_ID,
            config.CONFIG_HASH, config.RUBRIC_VERSION, review.team_id, review.symbol, review.original_action.value,
            review.reviewed_action.value, review.original_confidence, review.reviewed_confidence,
            review.risk_score, review.outcome_predicted, int(review.approved), json.dumps(review.modifications),
            review.review_notes, review.review_timestamp.isoformat(), review.actual_outcome,
            review.actual_pnl_pct, int(review.reviewer_was_correct) if review.reviewer_was_correct is not None else None
        ))
        
        conn.commit()
        conn.close()
    
    def save_portfolio_snapshot(self, portfolio: VirtualPortfolio, date_str: str):
        """Save daily portfolio snapshot"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("""
        INSERT OR REPLACE INTO portfolio_snapshots (
            snapshot_date, experiment_id, config_hash, team_id, total_value, cash, total_return_pct,
            max_drawdown, sharpe_ratio, sortino_ratio, calmar_ratio, recovery_factor,
            winning_trades, losing_trades, total_trades, api_costs, success_rate, avg_pnl
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            date_str, self.cfg.EXPERIMENT_ID, self.cfg.CONFIG_HASH, portfolio.team_id,
            portfolio.total_value, portfolio.cash, portfolio.total_return_pct,
            portfolio.max_drawdown, portfolio.sharpe_ratio, portfolio.sortino_ratio,
            portfolio.calmar_ratio, portfolio.recovery_factor, portfolio.winning_trades,
            portfolio.losing_trades, portfolio.total_trades, portfolio.api_costs,
            portfolio.success_rate, portfolio.avg_pnl
        ))
        
        conn.commit()
        conn.close()
    
    def get_reviewer_training_data(self, days: int = 30) -> pd.DataFrame:
        """Get training data for reviewer calibration"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        
        query = f"""
        SELECT 
            rd.review_id,
            rd.risk_score,
            rd.outcome_predicted,
            rd.reviewer_was_correct,
            rd.actual_outcome,
            rd.actual_pnl_pct,
            p.market_regime,
            p.exit_type,
            p.patterns
        FROM review_decisions rd
        JOIN positions p ON rd.recommendation_id = p.recommendation_id
        WHERE rd.review_timestamp >= datetime('now', '-{days} days')
        AND rd.actual_outcome IS NOT NULL
        """
        
        df = pd.read_sql(query, conn)
        conn.close()
        return df

# ============================================================================
# TOURNAMENT DASHBOARD
# ============================================================================

class TournamentDashboard:
    """Dashboard for monitoring reviewer accuracy and pattern effectiveness"""
    
    def __init__(self, db: EnhancedTournamentDatabase):
        self.db = db
        self.logger = logging.getLogger("Dashboard")
    
    def generate_reviewer_accuracy_report(self, days: int = 30) -> str:
        """Generate comprehensive accuracy report with regime breakdown"""
        df = self.db.get_reviewer_training_data(days)
        
        if df.empty:
            return "No data available"
        
        df['risk_bucket'] = pd.cut(df['risk_score'], bins=[0, 40, 60, 80, 100], 
                                  labels=['Low', 'Medium', 'High', 'Very High'])
        
        pattern_stats = self._analyze_pattern_effectiveness(df)
        
        regime_accuracy = df.groupby('market_regime')['reviewer_correct'].agg(['count', 'mean']) if 'market_regime' in df.columns else pd.DataFrame()
        
        exit_type_performance = df.groupby('exit_type')['actual_pnl_pct'].agg(['mean', 'count']) if 'exit_type' in df.columns else pd.DataFrame()
        
        report = f"""
üìä Reviewer Accuracy Report (Last {days} Days)
{'='*50}

Overall Accuracy: {df['reviewer_correct'].mean():.1%}
Total Trades Reviewed: {len(df)}

By Outcome Prediction:
{df.groupby('outcome_predicted')['reviewer_correct'].agg(['count', 'mean']).to_string()}

By Risk Score Bucket:
{df.groupby('risk_bucket')['reviewer_correct'].agg(['count', 'mean']).to_string()}

By Regime:
{regime_accuracy.to_string() if not regime_accuracy.empty else 'No regime data'}

Top Performing Patterns:
{pattern_stats.head(10).to_string()}
"""
        
        return report
    
    def _analyze_pattern_effectiveness(self, df: pd.DataFrame) -> pd.Series:
        pattern_performance = defaultdict(list)
        
        for _, row in df.iterrows():
            patterns = json.loads(row['patterns']) if isinstance(row['patterns'], str) else []
            for pattern in patterns:
                pattern_performance[pattern].append(row['actual_pnl_pct'])
        
        stats = []
        for pattern, pnls in pattern_performance.items():
            if len(pnls) >= 3:
                stats.append({
                    'pattern': pattern,
                    'avg_pnl': np.mean(pnls),
                    'win_rate': len([p for p in pnls if p > 0]) / len(pnls) * 100,
                    'count': len(pnls)
                })
        
        pattern_df = pd.DataFrame(stats)
        if not pattern_df.empty:
            return pattern_df.set_index('pattern')['avg_pnl'].sort_values(ascending=False)
        
        return pd.Series()

# ============================================================================
# TRADE REVIEWER
# ============================================================================

class TradeReviewer:
    """Enhanced reviewer with pattern recognition and learning"""
    
    def __init__(self, config: TournamentConfig, db: EnhancedTournamentDatabase):
        self.cfg = config
        self.db = db
        self.client = Anthropic(api_key=config.ANTHROPIC_API_KEY)
        self.vector_memory = None  # Set by orchestrator
        self.logger = logging.getLogger("Reviewer")
    
    def review_recommendation(self, rec: TeamRecommendation, stock: FilterResult,
                             portfolio: VirtualPortfolio, tournament_state: Dict = None) -> ReviewResult:
        """Review AI recommendation with risk assessment"""
        
        patterns = PatternExtractor.extract(rec.reasoning)
        
        # Calculate risk score
        risk_score = self._calculate_risk_score(rec, stock, portfolio, patterns)
        
        # Predict outcome
        outcome_predicted = "profit" if rec.confidence > 70 and risk_score < 50 else "loss" if risk_score > 70 else "uncertain"
        
        # Create review notes
        modifications = []
        
        if rec.confidence > 85 and risk_score > 60:
            modifications.append("Confidence reduced due to high risk")
            reviewed_confidence = min(70, rec.confidence - 15)
        else:
            reviewed_confidence = rec.confidence
        
        if rec.action in [TradeAction.STRONG_BUY, TradeAction.STRONG_SELL]:
            reviewed_action = TradeAction.BUY if rec.action == TradeAction.STRONG_BUY else TradeAction.SELL
            modifications.append("Strong action moderated")
        else:
            reviewed_action = rec.action
        
        approved = risk_score < 75 and reviewed_confidence > 40
        
        review_notes = f"Risk Score: {risk_score:.1f}. Patterns: {', '.join(patterns[:3])}"
        
        return ReviewResult(
            recommendation_id=rec.recommendation_id,
            team_id=rec.team_id,
            symbol=rec.symbol,
            original_action=rec.action,
            reviewed_action=reviewed_action,
            original_confidence=rec.confidence,
            reviewed_confidence=reviewed_confidence,
            original_reasoning=rec.reasoning,
            review_notes=review_notes,
            approved=approved,
            modifications=modifications,
            risk_score=risk_score,
            outcome_predicted=outcome_predicted
        )
    
    def _calculate_risk_score(self, rec: TeamRecommendation, stock: FilterResult,
                            portfolio: VirtualPortfolio, patterns: List[str]) -> float:
        """Calculate comprehensive risk score"""
        risk_factors = []
        
        # Technical risk
        if stock.stock_data.rsi > 75 or stock.stock_data.rsi < 25:
            risk_factors.append(30)
        elif stock.stock_data.rsi > 65 or stock.stock_data.rsi < 35:
            risk_factors.append(15)
        
        # Volatility risk
        if stock.stock_data.atr and stock.stock_data.price:
            vol_pct = (stock.stock_data.atr / stock.stock_data.price) * 100
            if vol_pct > 5:
                risk_factors.append(25)
            elif vol_pct > 3:
                risk_factors.append(10)
        
        # Concentration risk
        symbol_positions = sum(1 for pos in portfolio.positions.values() if pos.symbol == rec.symbol)
        if symbol_positions > 0:
            risk_factors.append(20 * symbol_positions)
        
        # Pattern risk
        high_risk_patterns = ['overbought', 'oversold', 'breakout_resistance']
        if any(p in patterns for p in high_risk_patterns):
            risk_factors.append(15)
        
        return min(100, sum(risk_factors) / len(risk_factors) if risk_factors else 30)
    
    def calibrate_reviewer(self):
        """Weekly calibration based on actual outcomes"""
        self.logger.info("Running reviewer calibration...")
        
        # Get recent review decisions with outcomes
        conn = sqlite3.connect(self.cfg.DB_FILE)
        query = """
        SELECT risk_score, outcome_predicted, actual_outcome, reviewer_was_correct
        FROM review_decisions
        WHERE actual_outcome IS NOT NULL
        AND review_timestamp >= datetime('now', '-7 days')
        """
        df = pd.read_sql(query, conn)
        conn.close()
        
        if len(df) < 10:
            self.logger.warning("Insufficient data for calibration")
            return
        
        accuracy = df['reviewer_was_correct'].mean()
        self.logger.info(f"Reviewer accuracy: {accuracy:.1%}")

# ============================================================================
# CROSS-TEAM LEARNER
# ============================================================================

class CrossTeamLearner:
    """Share anonymized patterns across teams for collective learning"""
    
    def __init__(self, tournament_memory: TournamentMemory):
        self.tournament_memory = tournament_memory
        self.anonymized_patterns = []
    
    def get_anonymized_patterns(self, team_id: int) -> List[Dict]:
        """Get patterns from other teams without revealing identities"""
        state = self.tournament_memory.get_tournament_state()
        all_patterns = []
        
        for tid, perf in self.tournament_memory.team_performance.items():
            if tid == team_id:
                continue
            
            for pattern, score in perf['patterns'].items():
                if score > 2:  # Only successful patterns
                    all_patterns.append({
                        'pattern': pattern,
                        'score': score,
                        'source_team': f"Team_{tid}",
                        'anonymized': True
                    })
        
        # Sort by score and return top patterns
        all_patterns.sort(key=lambda x: x['score'], reverse=True)
        return all_patterns[:5]

# ============================================================================
# LEARNING ENGINE
# ============================================================================

class LearningEngine:
    """Handles recursive self-improvement through retraining triggers"""
    
    def __init__(self, config: TournamentConfig, db: EnhancedTournamentDatabase,
                 vector_memory: VectorMemoryStore):
        self.cfg = config
        self.db = db
        self.vector_memory = vector_memory
        self.logger = logging.getLogger("LearningEngine")
    
    def calibrate_reviewer(self):
        """Trigger reviewer retraining based on performance"""
        self.logger.info("üîÑ Initiating reviewer retraining cycle...")
        
        # Get training data
        df = self.db.get_reviewer_training_data(days=30)
        
        if df.empty or len(df) < 20:
            self.logger.warning("Insufficient training data")
            return
        
        # Analyze pattern effectiveness by regime
        regime_analysis = self._analyze_by_regime(df)
        
        # Update rubric weights based on analysis
        self._update_rubric_weights(regime_analysis)
        
        # Generate recommendations for next iteration
        self._generate_improvement_report(regime_analysis)
    
    def _analyze_by_regime(self, df: pd.DataFrame) -> Dict:
        """Analyze performance patterns by market regime"""
        if 'market_regime' not in df.columns:
            return {}
        
        analysis = {}
        for regime in df['market_regime'].unique():
            regime_data = df[df['market_regime'] == regime]
            analysis[regime] = {
                'sample_size': len(regime_data),
                'accuracy': regime_data['reviewer_correct'].mean(),
                'avg_pnl': regime_data['actual_pnl_pct'].mean(),
                'top_patterns': self._extract_top_patterns(regime_data)
            }
        
        return analysis
    
    def _extract_top_patterns(self, df: pd.DataFrame) -> List[Tuple[str, float]]:
        """Extract top performing patterns from data"""
        pattern_performance = defaultdict(list)
        
        for _, row in df.iterrows():
            patterns = json.loads(row['patterns']) if isinstance(row['patterns'], str) else []
            for pattern in patterns:
                pattern_performance[pattern].append(row['actual_pnl_pct'])
        
        # Calculate average P&L per pattern
        pattern_scores = []
        for pattern, pnls in pattern_performance.items():
            if len(pnls) >= 3:
                avg_pnl = np.mean(pnls)
                pattern_scores.append((pattern, avg_pnl))
        
        return sorted(pattern_scores, key=lambda x: x[1], reverse=True)[:5]
    
    def _update_rubric_weights(self, analysis: Dict):
        """Update reviewer rubric based on pattern analysis"""
        # In production, this would update actual weights
        # For now, log the recommendations
        for regime, data in analysis.items():
            self.logger.info(f"Regime {regime}: Accuracy {data['accuracy']:.1%}, Top patterns: {data['top_patterns']}")
    
    def _generate_improvement_report(self, analysis: Dict):
        """Generate report for human review"""
        report_path = Path(f"learning_report_{self.cfg.EXPERIMENT_ID}.json")
        with open(report_path, 'w') as f:
            json.dump(analysis, f, indent=2)
        
        self.logger.info(f"Learning report saved: {report_path}")

# ============================================================================
# STRATEGY OPTIMIZER
# ============================================================================

class StrategyOptimizer:
    """Analyze tournament memory to optimize trading strategies"""
    
    def __init__(self, tournament_memory: TournamentMemory):
        self.tournament_memory = tournament_memory
        self.logger = logging.getLogger("StrategyOptimizer")
    
    def optimize_position_sizing(self, team_id: int, symbol: str,
                               patterns: List[str], regime: MarketRegime) -> float:
        """Dynamic position sizing based on pattern/regime performance"""
        perf = self.tournament_memory.team_performance.get(team_id)
        if not perf or not perf['patterns']:
            return 1.0
        
        # Find pattern performance scores
        pattern_scores = []
        for pattern in patterns[:2]:  # Top 2 patterns
            if pattern in perf['patterns']:
                pattern_scores.append(perf['patterns'][pattern])
        
        if not pattern_scores:
            return 1.0
        
        # Calculate multiplier (0.5 to 1.5 range)
        avg_score = np.mean(pattern_scores)
        multiplier = 1.0 + (avg_score / 10.0)  # Scale score to multiplier
        
        return max(0.5, min(1.5, multiplier))

# ============================================================================
# MAIN TOURNAMENT ORCHESTRATOR - KIMI READY
# ============================================================================

class RecursiveTournamentOrchestrator:
    """Main orchestrator with Kimi API integration"""
    
    def __init__(self, config: TournamentConfig):
        self.cfg = config
        self.setup_logging()
        
        self.logger = logging.getLogger("Tournament")
        self.filter = SmartFilter(config)
        self.db = EnhancedTournamentDatabase(config)
        
        # Initialize memory systems
        if chromadb and embedding_functions:
            self.vector_memory = VectorMemoryStore(config)
        else:
            self.vector_memory = None
            logging.warning("Vector memory disabled - ChromaDB not available")
        
        self.tournament_memory = TournamentMemory()
        self.strategy_optimizer = StrategyOptimizer(self.tournament_memory)
        
        # Initialize reviewer
        self.reviewer = TradeReviewer(config, self.db)
        self.reviewer.vector_memory = self.vector_memory
        
        # Initialize dashboard
        self.dashboard = TournamentDashboard(self.db)
        
        # Initialize AI teams
        self.teams = {}
        if 1 in config.ACTIVE_TEAMS and config.ANTHROPIC_API_KEY and Anthropic:
            self.teams[1] = AI_Team_Claude(config, self.vector_memory, self.tournament_memory)
        if 2 in config.ACTIVE_TEAMS and config.DEEPSEEK_API_KEY and OpenAI:
            self.teams[2] = AI_Team_DeepSeek(config, self.vector_memory, self.tournament_memory)
        if 3 in config.ACTIVE_TEAMS and config.KIMI_API_KEY and OpenAI:  # Kimi check
            self.teams[3] = AI_Team_Kimi(config, self.vector_memory, self.tournament_memory)
        if 4 in config.ACTIVE_TEAMS and config.GOOGLE_API_KEY and genai:
            self.teams[4] = AI_Team_Gemini(config, self.vector_memory, self.tournament_memory)
        
        # Initialize portfolios
        self.portfolios = {
            team_id: VirtualPortfolio(
                team_id=team_id,
                team_name=team.team_name,
                initial_capital=config.INITIAL_VIRTUAL_CAPITAL,
                cash=config.INITIAL_VIRTUAL_CAPITAL
            )
            for team_id, team in self.teams.items()
        }
        
        self.price_cache = {}
        
        print("\n" + "="*90)
        print("üèÜ ULTIMATE AI TRADING TOURNAMENT - KIMI API EDITION")
        print("="*90)
        print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üìä Watchlist: {len(config.WATCHLIST)} stocks")
        print(f"üë• Active Teams: {len(self.teams)}")
        print(f"üî¨ Experiment ID: {config.EXPERIMENT_ID}")
        print(f"üìù Config Hash: {config.CONFIG_HASH[:12]}...")
        print(f"üìã Rubric Version: {config.RUBRIC_VERSION}")
        for team_id, team in self.teams.items():
            print(f"   Team {team_id}: {team.team_name}")
        print(f"üí∞ Initial Capital per Team: ${config.INITIAL_VIRTUAL_CAPITAL:,.2f}")
        print("="*90)
    
    def setup_logging(self):
        logging.basicConfig(
            level=getattr(logging, self.cfg.LOG_LEVEL),
            format='%(asctime)s | %(name)-25s | %(levelname)-8s | %(message)s',
            handlers=[
                logging.FileHandler(self.cfg.LOG_FILE, mode='a'),
                logging.StreamHandler()
            ]
        )
    
    def update_all_prices(self):
        print("\nüì° Updating market prices...")
        symbols = list(set(
            [pos.symbol for portfolio in self.portfolios.values() for pos in portfolio.positions.values()] +
            self.cfg.WATCHLIST
        ))
        
        for symbol in symbols:
            try:
                stock = yf.Ticker(symbol)
                hist = stock.history(period='1d')
                if not hist.empty:
                    self.price_cache[symbol] = hist['Close'].iloc[-1]
                else:
                    self.price_cache[symbol] = self.price_cache.get(symbol, 0)
            except:
                self.price_cache[symbol] = self.price_cache.get(symbol, 0)
    
    def run_daily_tournament(self):
        """Run complete daily cycle with all features"""
        
        print("\n" + "="*90)
        print("üèÅ DAILY TOURNAMENT CYCLE")
        print("="*90)
        
        self.update_all_prices()
        
        # Update market regime for each portfolio
        print("\nüìä STEP 1: Detect Market Regimes")
        print("‚îÄ" * 85)
        for team_id, portfolio in self.portfolios.items():
            # Use SPY as proxy for regime
            spy = yf.Ticker("SPY").history(period='30d')
            portfolio.current_regime = MarketRegimeDetector().detect(self.price_cache.get('SPY', 450), spy)
            print(f"ü§ñ {portfolio.team_name}: Regime = {portfolio.current_regime.value}")
        
        # Portfolio review
        print("\nüìä STEP 2: Portfolio Review & Self-Critique")
        print("‚îÄ" * 85)
        
        for team_id, portfolio in self.portfolios.items():
            if not portfolio.positions:
                print(f"\nü§ñ {portfolio.team_name}: No open positions")
                continue
            
            print(f"\nü§ñ {portfolio.team_name} - Reviewing {len(portfolio.positions)} positions:")
            
            team = self.teams[team_id]
            
            for symbol, position in list(portfolio.positions.items()):
                current_price = self.price_cache.get(symbol, position.current_price)
                
                # Determine exit type
                exit_type = ExitType.DISCRETIONARY
                
                # Check stop loss
                if position.stop_loss and position.action in [TradeAction.BUY, TradeAction.STRONG_BUY]:
                    if current_price <= position.stop_loss:
                        exit_type = ExitType.STOP_LOSS
                        print(f"  üî¥ STOP LOSS: {symbol} @ ${current_price:.2f}")
                        portfolio.close_position(symbol, current_price, "Stop Loss Hit")
                        self.db.save_position(position, self.cfg)
                        
                        critique = team.self_critique(position, portfolio.current_regime)
                        if critique:
                            print(f"  üí≠ Critique: {critique.critique_text[:80]}...")
                            position.critiqued = True
                        continue
                
                # Check target
                if position.target_price and position.action in [TradeAction.BUY, TradeAction.STRONG_BUY]:
                    if current_price >= position.target_price:
                        exit_type = ExitType.TARGET_HIT
                        print(f"  üéØ TARGET HIT: {symbol} @ ${current_price:.2f}")
                        portfolio.close_position(symbol, current_price, "Target Hit")
                        self.db.save_position(position, self.cfg)
                        
                        critique = team.self_critique(position, portfolio.current_regime)
                        if critique:
                            print(f"  üí≠ Critique: {critique.critique_text[:80]}...")
                            position.critiqued = True
                        continue
                
                # Check expiration
                days_held = (datetime.now() - position.entry_timestamp).days
                if days_held >= 30:
                    exit_type = ExitType.TIME_EXPIRED
                    print(f"  ‚è±Ô∏è  EXPIRED: {symbol} (held {days_held} days)")
                    portfolio.close_position(symbol, current_price, "Time Expired")
                    self.db.save_position(position, self.cfg)
                    
                    critique = team.self_critique(position, portfolio.current_regime)
                    if critique:
                        print(f"  üí≠ Critique: {critique.critique_text[:80]}...")
                        position.critiqued = True
                    continue
                
                # Update unrealized P&L
                position.update_market_price(current_price)
                pnl_pct = position.unrealized_pnl / position.position_value * 100
                print(f"  üìà {symbol}: ${position.unrealized_pnl:+.2f} ({pnl_pct:+.1f}%)")
        
        # Find new opportunities
        print("\nüîç STEP 3: Find New Opportunities")
        print("‚îÄ" * 85)
        
        screened = self.filter.tier1_technical_screen(self.cfg.WATCHLIST)
        if not screened:
            print("‚úÖ No stocks passed screening today")
            return
        
        print(f"\nüéØ {len(screened)} stocks for AI analysis\n")
        
        # Get tournament state
        tournament_state = self.tournament_memory.get_tournament_state()
        
        # Review loop
        print("\n‚öñÔ∏è  STEP 4: Review Layer Evaluation")
        print("‚îÄ" * 85)
        
        for team_id, team in self.teams.items():
            portfolio = self.portfolios[team_id]
            
            # Get cross-team patterns
            if hasattr(self, 'cross_team_learner'):
                team.cross_team_patterns = self.cross_team_learner.get_anonymized_patterns(team_id)
            
            print(f"\nü§ñ TEAM {team_id}: {team.team_name}")
            print("‚îÄ" * 85)
            
            reviewed_count = 0
            approved_count = 0
            
            for stock in screened[:self.cfg.MAX_DAILY_ANALYSIS]:
                rec = team.create_recommendation(stock, portfolio, tournament_state)
                if not rec:
                    print(f"  ‚ùå AI analysis failed")
                    continue
                
                # Save recommendation with experiment tracking
                rec_id = self.db.save_recommendation(rec, stock, self.cfg)
                
                # Reviewer evaluation
                review = self.reviewer.review_recommendation(rec, stock, portfolio, tournament_state)
                review.recommendation_id = rec_id
                review.config_hash = self.cfg.CONFIG_HASH
                
                print(f"\nüìä {stock.symbol} (Score: {stock.score})")
                print(f"  ü§ñ Team: {rec.action.value} @ {rec.confidence}%")
                print(f"  ‚öñÔ∏è  Reviewer: {'‚úÖ APPROVED' if review.approved else '‚ùå REJECTED'}")
                
                if review.modifications:
                    print(f"  üìù Modifications: {len(review.modifications)}")
                    for mod in review.modifications:
                        print(f"     - {mod}")
                
                # Save review decision
                self.db.save_review_result(review, self.cfg)
                
                reviewed_count += 1
                
                # Execute if approved
                if review.approved:
                    approved_count += 1
                    if review.reviewed_action in [TradeAction.BUY, TradeAction.STRONG_BUY]:
                        current_price = self.price_cache.get(stock.symbol, stock.stock_data.price)
                        
                        confidence_adj = review.reviewed_confidence - rec.confidence
                        size_modifier = (100 + confidence_adj) / 100 if confidence_adj < 0 else 1.0
                        
                        if portfolio.open_position(rec, current_price, stock.stock_data.atr, 
                                                  confidence_adj, size_modifier):
                            position = portfolio.positions[stock.symbol]
                            position.market_regime = portfolio.current_regime
                            self.db.save_position(position, self.cfg)
                else:
                    print(f"  ‚õî Trade blocked by reviewer")
                
                time.sleep(0.5)
            
            print(f"\n  üìä Reviewed: {reviewed_count} | Approved: {approved_count} | Rejected: {reviewed_count - approved_count}")
            print(f"  üí∞ API Cost: ${portfolio.api_costs:,.4f}")
        
        # Update portfolio values
        print("\nüìà STEP 5: Update Portfolio Values")
        print("‚îÄ" * 85)
        
        for team_id, portfolio in self.portfolios.items():
            portfolio.update_portfolio_value(self.price_cache)
            portfolio.calculate_advanced_metrics()
            
            today = datetime.now().date()
            portfolio.daily_pnl = portfolio.total_value - portfolio.initial_capital if today == datetime.now().date() else 0
            portfolio.daily_return_pct = portfolio.daily_pnl / (portfolio.total_value - portfolio.daily_pnl) * 100 if portfolio.total_value != portfolio.daily_pnl else 0
            
            print(f"ü§ñ {portfolio.team_name}: ${portfolio.total_value:,.2f} ({portfolio.total_return_pct:+.1f}%)")
            print(f"   Cash: ${portfolio.cash:,.2f} | P&L Today: ${portfolio.daily_pnl:+.2f}")
            print(f"   Sortino: {portfolio.sortino_ratio:.2f} | Calmar: {portfolio.calmar_ratio:.2f}")
            
            team = self.teams[team_id]
            team.update_performance_stats()
            portfolio.success_rate = team.success_rate
            portfolio.avg_pnl = team.avg_pnl
        
        # Weekly reviewer retraining
        if datetime.now().weekday() == self.cfg.REVIEWER_CALIBRATION_DAY:
            print("\nüß† STEP 6: Weekly Reviewer Retraining")
            print("‚îÄ" * 85)
            if hasattr(self, 'learning_engine'):
                self.learning_engine.calibrate_reviewer()
        
        # Save snapshots
        print("\nüíæ STEP 7: Save Data & Update Review Outcomes")
        print("‚îÄ" * 85)
        
        self._update_review_outcomes()
        self._save_daily_snapshots()
        
        print("‚úÖ Tournament cycle complete")
    
    def _update_review_outcomes(self):
        """Update review decisions with actual outcomes"""
        conn = sqlite3.connect(self.cfg.DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("""
        UPDATE review_decisions
        SET 
            actual_outcome = CASE 
                WHEN p.realized_pnl > 0 THEN 'profit'
                ELSE 'loss'
            END,
            actual_pnl_pct = (p.realized_pnl / p.position_value * 100),
            reviewer_was_correct = CASE
                WHEN (p.realized_pnl > 0 AND rd.outcome_predicted = 'profit') OR
                     (p.realized_pnl <= 0 AND rd.outcome_predicted = 'loss') THEN 1
                ELSE 0
            END
        FROM positions p
        JOIN review_decisions rd ON p.recommendation_id = rd.recommendation_id
        WHERE p.status = 'CLOSED'
        AND review_decisions.actual_outcome IS NULL
        AND review_decisions.experiment_id = ?
        """, (self.cfg.EXPERIMENT_ID,))
        
        updated = cursor.rowcount
        conn.commit()
        conn.close()
        
        self.logger.info(f"Updated {updated} review outcomes")
    
    def _save_daily_snapshots(self):
        """Save daily snapshots with experiment tracking"""
        today_str = datetime.now().date().isoformat()
        for team_id, portfolio in self.portfolios.items():
            self.db.save_portfolio_snapshot(portfolio, today_str)
            
            # Save daily P&L
            conn = sqlite3.connect(self.cfg.DB_FILE)
            cursor = conn.cursor()
            cursor.execute("""
            INSERT OR REPLACE INTO daily_pnl (date, experiment_id, team_id, daily_pnl, daily_return_pct)
            VALUES (?, ?, ?, ?, ?)
            """, (today_str, self.cfg.EXPERIMENT_ID, team_id, portfolio.daily_pnl, portfolio.daily_return_pct))
            conn.commit()
            conn.close()

    def display_leaderboard(self):
        """Display enhanced leaderboard"""
        print("\n" + "="*90)
        print("üèÜ TOURNAMENT LEADERBOARD")
        print("="*90)
        print(f"Experiment: {self.cfg.EXPERIMENT_ID} | Config: {self.cfg.CONFIG_HASH[:12]}...")
        
        state = self.tournament_memory.get_tournament_state()
        portfolio_data = []
        
        for team_id, portfolio in self.portfolios.items():
            rank = state['rankings'].get(team_id, len(self.portfolios))
            portfolio_data.append({
                'rank': rank,
                'team_id': team_id,
                'team_name': portfolio.team_name,
                'equity': portfolio.total_value,
                'return_pct': portfolio.total_return_pct,
                'drawdown': portfolio.max_drawdown,
                'win_rate': portfolio.success_rate,
                'trades': portfolio.total_trades,
                'costs': portfolio.api_costs,
                'sortino': portfolio.sortino_ratio,
                'calmar': portfolio.calmar_ratio
            })
        
        portfolio_data.sort(key=lambda x: x['rank'])
        
        # Print header
        print(f"\n{'Rank':<4} {'Team':<32} {'Equity':<12} {'Return':<7} {'DD':<6} {'Win%':<6} {'Trades':<6} {'API Cost':<8}")
        print("-" * 90)
        
        # Print each team's stats
        for data in portfolio_data:
            print(f"{data['rank']:<4} {data['team_name']:<32} "
                  f"${data['equity']:>10,.0f} {data['return_pct']:>+5.1f}% "
                  f"{data['drawdown']:>+5.1f}% {data['win_rate']:>5.1f}% "
                  f"{data['trades']:>5d} ${data['costs']:>6.2f}")
        
        print("="*90)

# ============================================================================
# MAIN EXECUTION BLOCK - KIMI READY
# ============================================================================

def main():
    """Main entry point with Kimi API support"""
    parser = argparse.ArgumentParser(description="üèÜ Ultimate AI Trading Tournament - Kimi Edition")
    parser.add_argument("--config", type=str, help="Path to config JSON file")
    parser.add_argument("--days", type=int, default=90, help="Tournament duration in days")
    parser.add_argument("--teams", type=str, default="1,2,3,4", help="Active team IDs")
    parser.add_argument("--watchlist", type=str, help="Custom watchlist file")
    parser.add_argument("--log-level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    
    args = parser.parse_args()
    
    # Load configuration
    config = TournamentConfig()
    config.TOURNAMENT_DAYS = args.days
    config.ACTIVE_TEAMS = [int(t) for t in args.teams.split(",")]
    config.LOG_LEVEL = args.log_level
    
    # Load custom config if provided
    if args.config and Path(args.config).exists():
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
            for key, value in custom_config.items():
                if hasattr(config, key):
                    setattr(config, key, value)
    
    # Load custom watchlist if provided
    if args.watchlist and Path(args.watchlist).exists():
        with open(args.watchlist, 'r') as f:
            config.WATCHLIST = [line.strip() for line in f if line.strip()]
    
    # Verify API keys before starting
    required_keys = {
        1: config.ANTHROPIC_API_KEY,
        2: config.DEEPSEEK_API_KEY,
        3: config.KIMI_API_KEY,  # Kimi key check
        4: config.GOOGLE_API_KEY
    }
    
    missing_teams = []
    for team_id, key in required_keys.items():
        if team_id in config.ACTIVE_TEAMS and not key:
            missing_teams.append(f"Team {team_id}")
    
    if missing_teams and len(missing_teams) == len(config.ACTIVE_TEAMS):
        print("‚ùå ERROR: No valid API keys found for active teams!")
        print("Please set at least one of: ANTHROPIC_API_KEY, DEEPSEEK_API_KEY, KIMI_API_KEY, GOOGLE_API_KEY")
        sys.exit(1)
    
    # Initialize orchestrator
    orchestrator = RecursiveTournamentOrchestrator(config)
    
    # Add missing components if memory is available
    if orchestrator.vector_memory:
        orchestrator.cross_team_learner = CrossTeamLearner(orchestrator.tournament_memory)
        orchestrator.learning_engine = LearningEngine(config, orchestrator.db, orchestrator.vector_memory)
    
    # Run tournament
    try:
        print("\nüöÄ Starting tournament...")
        for day in range(config.TOURNAMENT_DAYS):
            print(f"\n{'='*90}")
            print(f"üìÖ DAY {day + 1} / {config.TOURNAMENT_DAYS}")
            print(f"{'='*90}")
            
            orchestrator.run_daily_tournament()
            orchestrator.display_leaderboard()
            
            # Show reviewer accuracy weekly
            if (day + 1) % 7 == 0:
                print("\n" + orchestrator.dashboard.generate_reviewer_accuracy_report(days=7))
            
            # Wait for next day
            if day < config.TOURNAMENT_DAYS - 1:
                print(f"\n‚è≥ Waiting for next day... (Ctrl+C to exit)")
                try:
                    time.sleep(86400)  # 24 hours
                except KeyboardInterrupt:
                    print("\nüèÅ Tournament interrupted by user")
                    break
        
        # Final results
        print("\n" + "="*90)
        print("üèÜ TOURNAMENT COMPLETE - FINAL RESULTS")
        print("="*90)
        orchestrator.display_leaderboard()
        
        # Save final report
        report = {
            "experiment_id": config.EXPERIMENT_ID,
            "config_hash": config.CONFIG_HASH,
            "final_leaderboard": orchestrator.tournament_memory.get_tournament_state(),
            "reviewer_accuracy": orchestrator.dashboard.generate_reviewer_accuracy_report(days=config.TOURNAMENT_DAYS)
        }
        
        with open(f"tournament_report_{config.EXPERIMENT_ID}.json", 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"\nüìÑ Full report saved to: tournament_report_{config.EXPERIMENT_ID}.json")
        
    except Exception as e:
        orchestrator.logger.error(f"Tournament failed: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()